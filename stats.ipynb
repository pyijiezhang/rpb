{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and stats for Uninformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- basic stats ----\n",
      "train_loss:  0.33650333333333327  ;  0.0015594657204739402\n",
      "test_loss:  0.32948  ;  0.004469183370594673\n",
      "risks:  0.4642566430720888  ;  0.001232512470557466\n",
      "---- further details ----\n",
      "train_loss:  0.33650333333333327  ;  0.0015594657204739402\n",
      "eval_loss:  0.33650333333333327  ;  0.0015594657204739402\n",
      "kln:  0.030372346598307294  ;  0.00020174082992161185\n",
      "risks:  0.4642566430720888  ;  0.001232512470557466\n",
      "test_loss:  0.32948  ;  0.004469183370594673\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Stats of Uninformed \"\"\"\n",
    "method = \"Uninformed\"\n",
    "name_data = \"mnist\" # mnist or fmnist\n",
    "model = \"fcn\" # fcn or cnn\n",
    "objective = \"fclassic\"\n",
    "seeds = np.arange(5)\n",
    "n_bound = 60000\n",
    "mc_samples = 60000\n",
    "delta_test=0.01\n",
    "delta=0.025\n",
    "\n",
    "kln = []\n",
    "risks = []\n",
    "train_loss = []\n",
    "eval_loss = []\n",
    "test_loss = []\n",
    "for seed in seeds:\n",
    "    exp_settings = f\"{name_data}_{model}_{objective}_{seed}.pt\"\n",
    "    results_dir = f\"./results/{method}/results_\" + exp_settings\n",
    "\n",
    "    with open(results_dir, \"rb\") as handle:\n",
    "        result_seed = pickle.load(handle)\n",
    "    ## read results\n",
    "    risks.append(result_seed[\"risk\"])\n",
    "    train_loss.append(result_seed[\"train_loss\"])\n",
    "    eval_loss.append(result_seed[\"train_loss\"]) # should be eval_loss\n",
    "    test_loss.append(result_seed[\"test_loss\"])\n",
    "    kln.append(result_seed[\"kl\"]/n_bound)\n",
    "\n",
    "# basic stats\n",
    "print(\"---- basic stats ----\")\n",
    "print(\"train_loss: \", np.mean(train_loss), \" ; \", np.std(train_loss))\n",
    "print(\"test_loss: \", np.mean(test_loss), \" ; \", np.std(test_loss))\n",
    "print(\"risks: \", np.mean(risks), \" ; \", np.std(risks))\n",
    "\n",
    "# further details\n",
    "print(\"---- further details ----\")\n",
    "## train loss\n",
    "print(\"train_loss: \", np.mean(train_loss), \" ; \", np.std(train_loss))\n",
    "## for bound\n",
    "print(\"eval_loss: \", np.mean(eval_loss), \" ; \", np.std(eval_loss))\n",
    "print(\"kln: \", np.mean(kln),\" ; \", np.std(kln))\n",
    "print(\"risks: \", np.mean(risks), \" ; \", np.std(risks))\n",
    "## test loss\n",
    "print(\"test_loss: \", np.mean(test_loss), \" ; \", np.std(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and stats for Informed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result_seed:  0 {'kl': array(80.83292, dtype=float32), 'risk': 0.3837803676549357, 'train_loss': 0.3415, 'eval_loss': 0.3379666666666667, 'test_loss': 0.34}\n",
      "result_seed:  1 {'kl': array(86.555855, dtype=float32), 'risk': 0.38910774574478296, 'train_loss': 0.34203333333333336, 'eval_loss': 0.342, 'test_loss': 0.3291}\n",
      "result_seed:  2 {'kl': array(81.00739, dtype=float32), 'risk': 0.3796732592069954, 'train_loss': 0.3402, 'eval_loss': 0.33393333333333336, 'test_loss': 0.3377}\n",
      "result_seed:  3 {'kl': array(82.6727, dtype=float32), 'risk': 0.3849526530601304, 'train_loss': 0.33741666666666664, 'eval_loss': 0.33873333333333333, 'test_loss': 0.3328}\n",
      "result_seed:  4 {'kl': array(80.542496, dtype=float32), 'risk': 0.38673049442256374, 'train_loss': 0.3463833333333333, 'eval_loss': 0.3409, 'test_loss': 0.3394}\n",
      "---- basic stats ----\n",
      "train_loss:  0.3415066666666667  ;  0.002915296821175431\n",
      "test_loss:  0.3358  ;  0.004197618372363074\n",
      "risks:  0.38484890401788163  ;  0.003150172958329321\n",
      "---- further details ----\n",
      "train_loss:  0.3415066666666667  ;  0.002915296821175431\n",
      "eval_loss:  0.33870666666666666  ;  0.0027924819704978425\n",
      "kln:  0.002744075724283854  ;  7.477479307773228e-05\n",
      "risks:  0.38484890401788163  ;  0.003150172958329321\n",
      "test_loss:  0.3358  ;  0.004197618372363074\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Stats of Informed \"\"\"\n",
    "method = \"Informed\"\n",
    "name_data = \"mnist\"\n",
    "model = \"fcn\"\n",
    "objective = \"fclassic\"\n",
    "seeds = np.arange(5)\n",
    "n_bound = 30000\n",
    "mc_samples = 30000\n",
    "delta_test=0.01\n",
    "delta=0.025\n",
    "\n",
    "kln = []\n",
    "risks = []\n",
    "train_loss = []\n",
    "eval_loss = []\n",
    "test_loss = []\n",
    "for seed in seeds:\n",
    "    exp_settings = f\"{name_data}_{model}_{objective}_{seed}.pt\"\n",
    "    results_dir = f\"./results/{method}/results_\" + exp_settings\n",
    "\n",
    "    with open(results_dir, \"rb\") as handle:\n",
    "        result_seed = pickle.load(handle)\n",
    "    \n",
    "    print(\"result_seed: \", seed, result_seed)\n",
    "    ## read results\n",
    "    risks.append(result_seed[\"risk\"])\n",
    "    train_loss.append(result_seed[\"train_loss\"])\n",
    "    eval_loss.append(result_seed[\"eval_loss\"])\n",
    "    test_loss.append(result_seed[\"test_loss\"])\n",
    "    kln.append(result_seed[\"kl\"]/n_bound)\n",
    "\n",
    "# basic stats\n",
    "print(\"---- basic stats ----\")\n",
    "print(\"train_loss: \", np.mean(train_loss), \" ; \", np.std(train_loss))\n",
    "print(\"test_loss: \", np.mean(test_loss), \" ; \", np.std(test_loss))\n",
    "print(\"risks: \", np.mean(risks), \" ; \", np.std(risks))\n",
    "\n",
    "# further details\n",
    "print(\"---- further details ----\")\n",
    "## Train loss\n",
    "print(\"train_loss: \", np.mean(train_loss), \" ; \", np.std(train_loss))\n",
    "## For bound\n",
    "print(\"eval_loss: \", np.mean(eval_loss), \" ; \", np.std(eval_loss))\n",
    "print(\"kln: \", np.mean(kln),\" ; \", np.std(kln))\n",
    "print(\"risks: \", np.mean(risks), \" ; \", np.std(risks))\n",
    "## Test loss\n",
    "print(\"test_loss: \", np.mean(test_loss), \" ; \", np.std(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and stats for InformedExcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result_seed:  0 {'kl': array(2326.7615, dtype=float32), 'risk': (0.3482941593104534, 0.027305699270062208, array([0.995     , 0.14223333], dtype=float32), 0.024566666666666667), 'train_loss': 0.15998333333333334, 'eval_loss': 0.1742, 'test_loss': 0.1531}\n",
      "result_seed:  1 {'kl': array(2331.6982, dtype=float32), 'risk': (0.35778204992820856, 0.027656394577770957, array([0.9949    , 0.14923333], dtype=float32), 0.0249), 'train_loss': 0.1701, 'eval_loss': 0.18626666666666666, 'test_loss': 0.1716}\n",
      "result_seed:  2 {'kl': array(2112.991, dtype=float32), 'risk': (0.342560562753538, 0.028392449512295893, array([0.9945667, 0.1441   ], dtype=float32), 0.0256), 'train_loss': 0.16436666666666666, 'eval_loss': 0.18233333333333332, 'test_loss': 0.1599}\n",
      "result_seed:  3 {'kl': array(2207.2212, dtype=float32), 'risk': (0.32614880357664827, 0.027305699270062208, array([0.9949333 , 0.12906666], dtype=float32), 0.024566666666666667), 'train_loss': 0.1503, 'eval_loss': 0.16356666666666667, 'test_loss': 0.1495}\n",
      "result_seed:  4 {'kl': array(2234.8726, dtype=float32), 'risk': (0.34644066005314117, 0.028637682105599176, array([0.9948, 0.1428], dtype=float32), 0.025833333333333333), 'train_loss': 0.16428333333333334, 'eval_loss': 0.18253333333333333, 'test_loss': 0.1632}\n",
      "---- basic stats ----\n",
      "train_loss:  0.16180666666666665  ;  0.0065908235870455216\n",
      "test_loss:  0.15946  ;  0.007761597773654598\n",
      "risks:  0.34424524712439786  ;  0.01034193394364561\n",
      "---- further details ----\n",
      "train_loss:  0.16180666666666665  ;  0.0065908235870455216\n",
      "kln:  0.07475696289062499  ;  0.0027134015644078063\n",
      "excess_loss:  0.13632665276527406  ;  0.006645453154189856\n",
      "excess_risk:  0.31638566217723973  ;  0.010243444776930071\n",
      "h_loss:  0.025093333333333336  ;  0.0005284778982028378\n",
      "h_risks:  0.027859584947158088  ;  0.0005557418187520534\n",
      "risks:  0.34424524712439786  ;  0.01034193394364561\n",
      "test_loss:  0.15946  ;  0.007761597773654598\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Stats of InformedExcess \"\"\"\n",
    "method = \"InformedExcess\"\n",
    "name_data = \"mnist\" # mnist or fmnist\n",
    "model = \"fcn\" # fcn or cnn\n",
    "objective = \"fclassic\"\n",
    "seeds = np.arange(5)\n",
    "n_bound = 30000\n",
    "mc_samples = 30000\n",
    "delta_test=0.01\n",
    "delta=0.025\n",
    "# Excess loss\n",
    "rv = np.array([-1, 0, 1])\n",
    "js = rv[1:]\n",
    "js_minus = rv[1:] - rv[0:-1]\n",
    "\n",
    "kln = [] # kl/n\n",
    "train_loss = []\n",
    "eval_loss = []\n",
    "excess_loss = []\n",
    "h_loss = []\n",
    "test_loss = []\n",
    "risks = [] # the risk\n",
    "excess_risks = [] # the excess risk\n",
    "h_risks = [] # reference classifier h risks\n",
    "\n",
    "for seed in seeds:\n",
    "    exp_settings = f\"{name_data}_{model}_{objective}_{seed}.pt\"\n",
    "    results_dir = f\"./results/{method}/results_\" + exp_settings\n",
    "\n",
    "    with open(results_dir, \"rb\") as handle:\n",
    "        result_seed = pickle.load(handle)\n",
    "    print(\"result_seed: \", seed, result_seed)\n",
    "\n",
    "    # Basic\n",
    "    risks.append(result_seed[\"risk\"][0])\n",
    "    h_risks.append(result_seed[\"risk\"][1])\n",
    "    excess_risks.append(result_seed[\"risk\"][0] - result_seed[\"risk\"][1])\n",
    "    train_loss.append(result_seed[\"train_loss\"])\n",
    "    test_loss.append(result_seed[\"test_loss\"])\n",
    "\n",
    "    # excess risk\n",
    "    excess_loss_1_seed = result_seed[\"risk\"][2][0]\n",
    "    excess_loss_2_seed = result_seed[\"risk\"][2][1]\n",
    "    excess_loss_seed = rv[0] + js_minus[0] * excess_loss_1_seed + js_minus[1] * excess_loss_2_seed\n",
    "    excess_loss.append(excess_loss_seed)\n",
    "    kl_seed = result_seed[\"kl\"] ; kln.append(kl_seed/n_bound)\n",
    "\n",
    "    # h risk\n",
    "    h_loss_seed = result_seed[\"risk\"][3] ; h_loss.append(h_loss_seed)\n",
    "\n",
    "# basic stats\n",
    "print(\"---- basic stats ----\")\n",
    "print(\"train_loss: \", np.mean(train_loss), \" ; \", np.std(train_loss))\n",
    "print(\"test_loss: \", np.mean(test_loss), \" ; \", np.std(test_loss))\n",
    "print(\"risks: \", np.mean(risks), \" ; \", np.std(risks))\n",
    "\n",
    "# further details\n",
    "print(\"---- further details ----\")\n",
    "## Train loss\n",
    "print(\"train_loss: \", np.mean(train_loss), \" ; \", np.std(train_loss))\n",
    "## For bound\n",
    "### excess bound\n",
    "print(\"kln: \", np.mean(kln),\" ; \", np.std(kln))\n",
    "print(\"excess_loss: \", np.mean(excess_loss), \" ; \", np.std(excess_loss))\n",
    "print(\"excess_risk: \", np.mean(excess_risks),\" ; \", np.std(excess_risks))\n",
    "### h bound\n",
    "print(\"h_loss: \", np.mean(h_loss), \" ; \", np.std(h_loss))\n",
    "print(\"h_risks: \", np.mean(h_risks), \" ; \", np.std(h_risks))\n",
    "### bound\n",
    "print(\"risks: \", np.mean(risks), \" ; \", np.std(risks))\n",
    "## Test loss\n",
    "print(\"test_loss: \", np.mean(test_loss), \" ; \", np.std(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and stats for Recursive PAC-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_posteriors:  [60000, 30000]\n"
     ]
    }
   ],
   "source": [
    "method = \"rpb\"\n",
    "name_data = \"mnist\" # mnist or fmnist\n",
    "model = \"fcn\" # fcn or cnn\n",
    "objective = \"fclassic\"\n",
    "\n",
    "T = 2 # 2, 4, 6, or 8\n",
    "split = \"geometric\"\n",
    "\n",
    "n_train = 60000\n",
    "if split == \"uniform\":\n",
    "    T_splits = [int(n_train / T)] * (T-1)\n",
    "    T_splits.append(n_train - int(n_train / T)*(T-1))\n",
    "elif split == \"geometric\":\n",
    "    if T == 2:\n",
    "        T_splits = [30000, 30000]\n",
    "    elif T == 4:\n",
    "        T_splits = [7500, 7500, 15000, 30000]\n",
    "    elif T == 6:\n",
    "        T_splits = [1875, 1875, 3750, 7500, 15000, 30000]\n",
    "    elif T == 8:\n",
    "        T_splits = [468, 469, 938, 1875, 3750, 7500, 15000, 30000]\n",
    "n_train_t_cumsum = np.cumsum(T_splits)\n",
    "n_posteriors = [n_train - n_train_t_cumsum[t - 2] for t in range(1, T + 1)]\n",
    "n_posteriors[0] = n_train\n",
    "print(\"n_posteriors: \", n_posteriors)\n",
    "\n",
    "gamma_t = 0.5\n",
    "# Excess loss\n",
    "rv = np.array([-gamma_t, 0, 1-gamma_t, 1])\n",
    "js = rv[1:]\n",
    "js_minus = rv[1:] - rv[0:-1]\n",
    "\n",
    "recursive_step_1 = False # Use B_1\n",
    "risk_laststep = False\n",
    "seeds = np.arange(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './results/rpb/results_mnist_fcn_fclassic_uniform_2_False_False_0.5_0.pt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m exp_settings \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname_data\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobjective\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrecursive_step_1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrisk_laststep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgamma_t\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mseed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     10\u001b[0m results_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./results/rpb/results_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m exp_settings\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresults_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m     12\u001b[0m     results \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(handle)\n\u001b[1;32m     14\u001b[0m kl_seeds\u001b[38;5;241m.\u001b[39mappend(results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkl\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/envs/multi-stage-pacbayes/lib/python3.10/site-packages/IPython/core/interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    322\u001b[0m     )\n\u001b[0;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './results/rpb/results_mnist_fcn_fclassic_uniform_2_False_False_0.5_0.pt'"
     ]
    }
   ],
   "source": [
    "kl_seeds = []\n",
    "excess_risk_seeds = []\n",
    "risk_seeds = []\n",
    "train_loss_seeds = []\n",
    "test_loss_seeds = []\n",
    "for seed in seeds:\n",
    "\n",
    "    exp_settings = f\"{name_data}_{model}_{objective}_{split}_{T}_{recursive_step_1}_{risk_laststep}_{gamma_t}_{seed}.pt\"\n",
    "\n",
    "    results_dir = f\"./results/rpb/results_\" + exp_settings\n",
    "    with open(results_dir, \"rb\") as handle:\n",
    "        results = pickle.load(handle)\n",
    "\n",
    "    kl_seeds.append(results[\"kl\"])\n",
    "    excess_risk_seeds.append(results[\"excess_risk\"]) # E_t\n",
    "    risk_seeds.append(results[\"risk\"]) # B_t\n",
    "    train_loss_seeds.append(results[\"train_loss\"])\n",
    "    test_loss_seeds.append(results[\"test_loss\"])\n",
    "\n",
    "kl_seeds = np.array(kl_seeds)\n",
    "excess_risk_seeds = np.array(excess_risk_seeds)\n",
    "risk_seeds = np.array(risk_seeds)\n",
    "train_loss_seeds = np.array(train_loss_seeds)\n",
    "test_loss_seeds = np.array(test_loss_seeds)\n",
    "\n",
    "# basic stats\n",
    "print(\"---- basic stats ----\")\n",
    "print(\"train_loss: \", train_loss_seeds.mean(0), \" ; \", train_loss_seeds.std(0))\n",
    "print(\"test_loss: \", test_loss_seeds.mean(0)[-1], \" ; \", test_loss_seeds.std(0)[-1])\n",
    "print(\"risks: \", risk_seeds.mean(0)[-1], \" ; \", risk_seeds.std(0)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- further details ----\n",
      "test_loss in rpb\n",
      "mean:  [0.34166 0.13638 0.11482 0.10584 0.098   0.09554]\n",
      "std:  [0.00452    0.00320337 0.00216185 0.00217954 0.00186869 0.0017625 ]\n",
      "B_t in rpb\n",
      "mean:  [0.45416848 0.38498419 0.30313124 0.24420018 0.20476847 0.18565702]\n",
      "std:  [0.0057251  0.00335994 0.00181273 0.00193779 0.00162876 0.00202064]\n",
      "E_t in rpb\n",
      "mean:  [0.15789995 0.11063915 0.09263456 0.08266838 0.08327278]\n",
      "std:  [0.00309851 0.0022632  0.00129615 0.00144103 0.0025285 ]\n",
      "kln in rpb\n",
      "mean:  [0.01871792 0.05630976 0.00963022 0.00437401 0.00318368 0.00264056]\n",
      "std:  [0.00024784 0.00110821 0.00034405 0.00028584 0.00010943 0.00012382]\n"
     ]
    }
   ],
   "source": [
    "print(\"---- further details ----\")\n",
    "print(\"test_loss in rpb\")\n",
    "print(\"mean: \", test_loss_seeds.mean(0))\n",
    "print(\"std: \", test_loss_seeds.std(0))\n",
    "print(\"B_t in rpb\")\n",
    "print(\"mean: \", risk_seeds.mean(0))\n",
    "print(\"std: \", risk_seeds.std(0))\n",
    "print(\"E_t in rpb\")\n",
    "print(\"mean: \", excess_risk_seeds.mean(0))\n",
    "print(\"std: \", excess_risk_seeds.std(0))\n",
    "print(\"kln in rpb\")\n",
    "print(\"mean: \", (kl_seeds / n_posteriors).mean(0))\n",
    "print(\"std: \", (kl_seeds / n_posteriors).std(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More on excess losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.36043333333333333,\n",
       " array([0.74940217, 0.14298494, 0.03363441], dtype=float32),\n",
       " array([0.9346667 , 0.11953778, 0.04177778], dtype=float32),\n",
       " array([0.95125717, 0.11177143, 0.03944762], dtype=float32),\n",
       " array([0.9535111 , 0.10024445, 0.0344    ], dtype=float32),\n",
       " array([0.9631    , 0.1033    , 0.03763333], dtype=float32)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emp loss for B1 is  0.36043333333333333  with B_t  0.4541684779633818\n",
      "excess loss t =  1  is  -0.0369892418384552  with E_t  0.1578999483098555\n",
      "excess loss t =  2  is  0.04799112491309643  with E_t  0.11063914958110883\n",
      "excess loss t =  3  is  0.051238108426332474  with E_t  0.09263455925429699\n",
      "excess loss t =  4  is  0.044077783823013306  with E_t  0.08266838015835745\n",
      "excess loss t =  5  is  0.05201667360961437  with E_t  0.08327278171601249\n"
     ]
    }
   ],
   "source": [
    "print(\"emp loss for B1 is \", results[\"loss\"][0], \" with B_t \", risk_seeds.mean(0)[0])\n",
    "for t in range(1, T):\n",
    "    exc = (results[\"loss\"][t] * js_minus).sum(0) + rv[0]\n",
    "    print(\"excess loss t = \", t, \" is \", exc, \" with E_t \", excess_risk_seeds.mean(0)[t-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def KL(Q, P):\n",
    "    \"\"\"\n",
    "    Compute Kullback-Leibler (KL) divergence between distributions Q and P.\n",
    "    \"\"\"\n",
    "    return sum([q * np.log(q / p) if q > 0.0 else 0.0 for q, p in zip(Q, P)])\n",
    "\n",
    "\n",
    "def KL_binomial(q, p):\n",
    "    \"\"\"\n",
    "    Compute the KL-divergence between two Bernoulli distributions of probability\n",
    "    of success q and p. That is, Q=(q,1-q), P=(p,1-p).\n",
    "    \"\"\"\n",
    "    return KL([q, 1.0 - q], [p, 1.0 - p])\n",
    "\n",
    "\n",
    "def get_binominal_inv(n, k, delta):\n",
    "    for p in np.linspace(1, 0, 100001):\n",
    "        if binom.pmf(k, n, p) >= delta:\n",
    "            return p\n",
    "\n",
    "\n",
    "def solve_kl_sup(q, right_hand_side):\n",
    "    \"\"\"\n",
    "    find x such that:\n",
    "        kl( q || x ) = right_hand_side\n",
    "        x > q\n",
    "    \"\"\"\n",
    "    f = lambda x: KL_binomial(q, x) - right_hand_side\n",
    "\n",
    "    if f(1.0 - 1e-9) <= 0.0:\n",
    "        return 1.0 - 1e-9\n",
    "    else:\n",
    "        return optimize.brentq(f, q, 1.0 - 1e-11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pbb_tight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
