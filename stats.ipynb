{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = \"rpb\"\n",
    "name_data=\"mnist\"\n",
    "model=\"fcn\"\n",
    "layers=4\n",
    "objective=\"fclassic\"\n",
    "T=6\n",
    "split=\"geometric\"\n",
    "gamma_t=0.5\n",
    "recursive_step_1=False\n",
    "T_splits = [1875, 1875, 3750, 7500, 15000, 30000]\n",
    "#T_splits = [7500, 7500, 15000, 30000]\n",
    "#T_splits = [30000,30000]\n",
    "T = len(T_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seeds = np.arange(5)\n",
    "seeds = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "risks = []\n",
    "train_loss = []\n",
    "test_loss = []\n",
    "for seed in seeds:\n",
    "    if method == \"rpb\":\n",
    "        exp_settings = f\"{name_data}_{model}_{layers}_{objective}_{split}_{T}_{recursive_step_1}_{gamma_t}_{seed}.pt\"\n",
    "    else:\n",
    "        exp_settings = f\"{name_data}_{model}_{layers}_{objective}_{split}_{seed}.pt\"\n",
    "    results_dir = f\"./results/{method}/results_\" + exp_settings\n",
    "\n",
    "    with open(results_dir, \"rb\") as handle:\n",
    "        result_seed = pickle.load(handle)\n",
    "\n",
    "    if method == \"Recursive-T\":\n",
    "        risks.append(result_seed[\"risk\"][-1])\n",
    "        train_loss.append(result_seed[\"train_loss\"][-1])\n",
    "        test_loss.append(result_seed[\"test_loss\"][-1])\n",
    "    elif method == \"InformedExcess\":\n",
    "        risks.append(result_seed[\"risk\"][0])\n",
    "        train_loss.append(result_seed[\"train_loss\"])\n",
    "        test_loss.append(result_seed[\"test_loss\"])\n",
    "    else:\n",
    "        risks.append(result_seed[\"risk\"])\n",
    "        train_loss.append(result_seed[\"train_loss\"])\n",
    "        test_loss.append(result_seed[\"test_loss\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19741307288013943\n",
      "0.0033783960836538856\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.20299642777491905,\n",
       " 0.19566946167410015,\n",
       " 0.19869031685484906,\n",
       " 0.19283831579347072,\n",
       " 0.19687084230335813]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.mean(risks))\n",
    "print(np.std(risks))\n",
    "risks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11054333333333335\n",
      "0.003165834978502687\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11161666666666667,\n",
       " 0.10875,\n",
       " 0.10566666666666667,\n",
       " 0.11511666666666667,\n",
       " 0.11156666666666666]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.mean(train_loss))\n",
    "print(np.std(train_loss))\n",
    "train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09214\n",
      "0.0013440238093129157\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0928, 0.0908, 0.0927, 0.0904, 0.094]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.mean(test_loss))\n",
    "print(np.std(test_loss))\n",
    "test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.3,\n",
       "  array([0.8020129 , 0.14513548, 0.03836559], dtype=float32),\n",
       "  array([0.93678224, 0.12458666, 0.0408    ], dtype=float32),\n",
       "  array([0.9446476 , 0.10830476, 0.03548571], dtype=float32),\n",
       "  array([0.96      , 0.10428889, 0.03495555], dtype=float32),\n",
       "  array([0.9637667 , 0.09813333, 0.03116667], dtype=float32)],\n",
       " 'kl': [array(1457.8726, dtype=float32),\n",
       "  array(2808.4126, dtype=float32),\n",
       "  array(535.4685, dtype=float32),\n",
       "  array(220.26709, dtype=float32),\n",
       "  array(115.32048, dtype=float32),\n",
       "  array(84.28107, dtype=float32)],\n",
       " 'excess_risk': [0.16308676228490693,\n",
       "  0.11427749912006058,\n",
       "  0.08604685879555296,\n",
       "  0.08279835605349539,\n",
       "  0.08163027525829492],\n",
       " 'risk': [0.41385722688535564,\n",
       "  0.37001537572758475,\n",
       "  0.299285186983853,\n",
       "  0.23568945228747945,\n",
       "  0.20064308219723512,\n",
       "  0.1819518163569125],\n",
       " 'train_loss': 0.09815,\n",
       " 'test_loss': [0.2915, 0.1405, 0.1188, 0.1012, 0.0979, 0.0937]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.021462365984916687"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exc = result_seed[\"loss\"][1]\n",
    "-0.5 + 0.5 * exc[0] + 0.5 * exc[1] + 0.5 * exc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def KL(Q, P):\n",
    "    \"\"\"\n",
    "    Compute Kullback-Leibler (KL) divergence between distributions Q and P.\n",
    "    \"\"\"\n",
    "    return sum([q * np.log(q / p) if q > 0.0 else 0.0 for q, p in zip(Q, P)])\n",
    "\n",
    "\n",
    "def KL_binomial(q, p):\n",
    "    \"\"\"\n",
    "    Compute the KL-divergence between two Bernoulli distributions of probability\n",
    "    of success q and p. That is, Q=(q,1-q), P=(p,1-p).\n",
    "    \"\"\"\n",
    "    return KL([q, 1.0 - q], [p, 1.0 - p])\n",
    "\n",
    "\n",
    "def get_binominal_inv(n, k, delta):\n",
    "    for p in np.linspace(1, 0, 100001):\n",
    "        if binom.pmf(k, n, p) >= delta:\n",
    "            return p\n",
    "\n",
    "\n",
    "def solve_kl_sup(q, right_hand_side):\n",
    "    \"\"\"\n",
    "    find x such that:\n",
    "        kl( q || x ) = right_hand_side\n",
    "        x > q\n",
    "    \"\"\"\n",
    "    f = lambda x: KL_binomial(q, x) - right_hand_side\n",
    "\n",
    "    if f(1.0 - 1e-9) <= 0.0:\n",
    "        return 1.0 - 1e-9\n",
    "    else:\n",
    "        return optimize.brentq(f, q, 1.0 - 1e-11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss:  0.36851  ;  0.0037168475292316708\n",
      "eval_loss:  0.36851  ;  0.0037168475292316708\n",
      "kln:  0.01543332255045573  ;  0.00013166799888221064\n",
      "risks:  0.4619243265818195  ;  0.003768512132500606\n",
      "test_loss:  0.37232  ;  0.005380483249671908\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Stats of Uninformed \"\"\"\n",
    "n_bound = 60000\n",
    "mc_samples = 60000\n",
    "delta_test=0.01\n",
    "delta=0.025\n",
    "method = \"Uninformed\"\n",
    "name_data = \"fmnist\"\n",
    "model = \"cnn\"\n",
    "objective = \"fclassic\"\n",
    "seeds = np.arange(5)\n",
    "\n",
    "kln = []\n",
    "risks = []\n",
    "train_loss = []\n",
    "eval_loss = []\n",
    "test_loss = []\n",
    "for seed in seeds:\n",
    "    exp_settings = f\"{name_data}_{model}_{objective}_{seed}.pt\"\n",
    "    results_dir = f\"./results/{method}/results_\" + exp_settings\n",
    "\n",
    "    with open(results_dir, \"rb\") as handle:\n",
    "        result_seed = pickle.load(handle)\n",
    "    ## Basic\n",
    "    risks.append(result_seed[\"risk\"])\n",
    "    train_loss.append(result_seed[\"train_loss\"])\n",
    "    eval_loss.append(result_seed[\"train_loss\"]) # should be eval_loss\n",
    "    test_loss.append(result_seed[\"test_loss\"])\n",
    "\n",
    "    kln.append(result_seed[\"kl\"]/n_bound)\n",
    "\n",
    "# train loss\n",
    "print(\"train_loss: \", np.mean(train_loss), \" ; \", np.std(train_loss))\n",
    "# for bound\n",
    "print(\"eval_loss: \", np.mean(eval_loss), \" ; \", np.std(eval_loss))\n",
    "print(\"kln: \", np.mean(kln),\" ; \", np.std(kln))\n",
    "print(\"risks: \", np.mean(risks), \" ; \", np.std(risks))\n",
    "# test loss\n",
    "print(\"test_loss: \", np.mean(test_loss), \" ; \", np.std(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result_seed:  0 {'kl': array(71.11655, dtype=float32), 'risk': 0.37849925130634987, 'train_loss': 0.33725, 'eval_loss': 0.33486666666666665, 'test_loss': 0.3362}\n",
      "result_seed:  1 {'kl': array(75.47776, dtype=float32), 'risk': 0.3834928933438333, 'train_loss': 0.33876666666666666, 'eval_loss': 0.3388, 'test_loss': 0.324}\n",
      "result_seed:  2 {'kl': array(71.56778, dtype=float32), 'risk': 0.3750388205977402, 'train_loss': 0.33898333333333336, 'eval_loss': 0.3314, 'test_loss': 0.3358}\n",
      "result_seed:  3 {'kl': array(73.19232, dtype=float32), 'risk': 0.37799861320456957, 'train_loss': 0.3353833333333333, 'eval_loss': 0.33393333333333336, 'test_loss': 0.3307}\n",
      "result_seed:  4 {'kl': array(71.14758, dtype=float32), 'risk': 0.3797721538435447, 'train_loss': 0.3419333333333333, 'eval_loss': 0.3361, 'test_loss': 0.3353}\n",
      "train_loss:  0.33846333333333334  ;  0.0021615683606533895\n",
      "eval_loss:  0.33502  ;  0.0024398178438381686\n",
      "kln:  0.0024166799418131506  ;  5.5694354537530375e-05\n",
      "risks:  0.37896034645920756  ;  0.002746594879694405\n",
      "test_loss:  0.3324  ;  0.004644566718220326\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Stats of Informed \"\"\"\n",
    "n_bound = 30000\n",
    "mc_samples = 30000\n",
    "delta_test=0.01\n",
    "delta=0.025\n",
    "method = \"Informed\"\n",
    "name_data = \"mnist\"\n",
    "model = \"fcn\"\n",
    "objective = \"fclassic\"\n",
    "seeds = np.arange(5)\n",
    "\n",
    "kln = []\n",
    "risks = []\n",
    "train_loss = []\n",
    "eval_loss = []\n",
    "test_loss = []\n",
    "for seed in seeds:\n",
    "    exp_settings = f\"{name_data}_{model}_{objective}_{seed}.pt\"\n",
    "    results_dir = f\"./results/{method}/results_\" + exp_settings\n",
    "\n",
    "    with open(results_dir, \"rb\") as handle:\n",
    "        result_seed = pickle.load(handle)\n",
    "    \n",
    "    print(\"result_seed: \", seed, result_seed)\n",
    "    ## Basic\n",
    "    risks.append(result_seed[\"risk\"])\n",
    "    train_loss.append(result_seed[\"train_loss\"])\n",
    "    eval_loss.append(result_seed[\"eval_loss\"])\n",
    "    test_loss.append(result_seed[\"test_loss\"])\n",
    "    kln.append(result_seed[\"kl\"]/n_bound)\n",
    "\n",
    "# Train loss\n",
    "print(\"train_loss: \", np.mean(train_loss), \" ; \", np.std(train_loss))\n",
    "# For bound\n",
    "print(\"eval_loss: \", np.mean(eval_loss), \" ; \", np.std(eval_loss))\n",
    "print(\"kln: \", np.mean(kln),\" ; \", np.std(kln))\n",
    "print(\"risks: \", np.mean(risks), \" ; \", np.std(risks))\n",
    "# Test loss\n",
    "print(\"test_loss: \", np.mean(test_loss), \" ; \", np.std(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result_seed:  0 {'kl': array(865.04755, dtype=float32), 'risk': (0.42857907672185014, 0.08991579254220548, array([0.97653335, 0.2221    ], dtype=float32), 0.08506666666666667), 'train_loss': 0.2833833333333333, 'test_loss': 0.2876}\n",
      "result_seed:  1 {'kl': array(879.98584, dtype=float32), 'risk': (0.41770111109182373, 0.0890955523978246, array([0.97443336, 0.21273333], dtype=float32), 0.08426666666666667), 'train_loss': 0.27216666666666667, 'test_loss': 0.2824}\n",
      "result_seed:  2 {'kl': array(876.2779, dtype=float32), 'risk': (0.4292791967207983, 0.09186336119398031, array([0.97466666, 0.2207    ], dtype=float32), 0.08696666666666666), 'train_loss': 0.28246666666666664, 'test_loss': 0.2895}\n",
      "result_seed:  3 {'kl': array(892.44244, dtype=float32), 'risk': (0.4327480367073655, 0.09193168430010411, array([0.9729667, 0.2231   ], dtype=float32), 0.08703333333333334), 'train_loss': 0.2843333333333333, 'test_loss': 0.2887}\n",
      "result_seed:  4 {'kl': array(901.6829, dtype=float32), 'risk': (0.4323154928381878, 0.08899301344623309, array([0.9741333 , 0.22446667], dtype=float32), 0.08416666666666667), 'train_loss': 0.2813333333333333, 'test_loss': 0.2887}\n",
      "train_loss:  0.2807366666666667  ;  0.004398514900887945\n",
      "kln:  0.029436244303385418  ;  0.00042550249399970065\n",
      "excess_loss:  0.19516667127609252  ;  0.00421082439029024\n",
      "excess_risk:  0.3377647020399356  ;  0.005000410455076819\n",
      "h_loss:  0.08549999999999999  ;  0.001264032348390569\n",
      "h_risks:  0.09035988077606952  ;  0.0012957690064262868\n",
      "risks:  0.4281245828160051  ;  0.005461291302685983\n",
      "test_loss:  0.28738  ;  0.002562342678097531\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Stats of InformedExcess \"\"\"\n",
    "n_bound = 30000\n",
    "mc_samples = 30000\n",
    "delta_test=0.01\n",
    "delta=0.025\n",
    "method = \"InformedExcess\"\n",
    "name_data = \"fmnist\"\n",
    "model = \"cnn\"\n",
    "objective = \"fclassic\"\n",
    "seeds = np.arange(5)\n",
    "# Excess loss\n",
    "rv = np.array([-1, 0, 1])\n",
    "js = rv[1:]\n",
    "js_minus = rv[1:] - rv[0:-1]\n",
    "\n",
    "kln = [] # kl/n\n",
    "train_loss = []\n",
    "eval_loss = []\n",
    "excess_loss = []\n",
    "h_loss = []\n",
    "test_loss = []\n",
    "risks = [] # the risk\n",
    "excess_risks = [] # the excess risk\n",
    "h_risks = [] # reference classifier h risks\n",
    "\n",
    "for seed in seeds:\n",
    "    exp_settings = f\"{name_data}_{model}_{objective}_{seed}.pt\"\n",
    "    results_dir = f\"./results/{method}/results_\" + exp_settings\n",
    "\n",
    "    with open(results_dir, \"rb\") as handle:\n",
    "        result_seed = pickle.load(handle)\n",
    "    print(\"result_seed: \", seed, result_seed)\n",
    "\n",
    "    ## Basic\n",
    "    risks.append(result_seed[\"risk\"][0])\n",
    "    h_risks.append(result_seed[\"risk\"][1])\n",
    "    excess_risks.append(result_seed[\"risk\"][0] - result_seed[\"risk\"][1])\n",
    "    train_loss.append(result_seed[\"train_loss\"])\n",
    "    test_loss.append(result_seed[\"test_loss\"])\n",
    "\n",
    "    # excess risk\n",
    "    excess_loss_1_seed = result_seed[\"risk\"][2][0]\n",
    "    excess_loss_2_seed = result_seed[\"risk\"][2][1]\n",
    "    excess_loss_seed = rv[0] + js_minus[0] * excess_loss_1_seed + js_minus[1] * excess_loss_2_seed\n",
    "    excess_loss.append(excess_loss_seed)\n",
    "    kl_seed = result_seed[\"kl\"] ; kln.append(kl_seed/n_bound)\n",
    "\n",
    "    # h risk\n",
    "    h_loss_seed = result_seed[\"risk\"][3] ; h_loss.append(h_loss_seed)\n",
    "\n",
    "# Train loss\n",
    "print(\"train_loss: \", np.mean(train_loss), \" ; \", np.std(train_loss))\n",
    "# For bound\n",
    "## excess bound\n",
    "print(\"kln: \", np.mean(kln),\" ; \", np.std(kln))\n",
    "print(\"excess_loss: \", np.mean(excess_loss), \" ; \", np.std(excess_loss))\n",
    "print(\"excess_risk: \", np.mean(excess_risks),\" ; \", np.std(excess_risks))\n",
    "## h bound\n",
    "print(\"h_loss: \", np.mean(h_loss), \" ; \", np.std(h_loss))\n",
    "print(\"h_risks: \", np.mean(h_risks), \" ; \", np.std(h_risks))\n",
    "## bound\n",
    "print(\"risks: \", np.mean(risks), \" ; \", np.std(risks))\n",
    "# Test loss\n",
    "print(\"test_loss: \", np.mean(test_loss), \" ; \", np.std(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result_seed:  0 {'loss': [0.24588333333333334, array([0.8829905 , 0.06594285, 0.06594285], dtype=float32), array([0.93648887, 0.05351111, 0.05351111], dtype=float32), array([0.9436, 0.0568, 0.0568], dtype=float32)], 'kl': [array(2982.1985, dtype=float32), array(386.2584, dtype=float32), array(85.042496, dtype=float32), array(51.494453, dtype=float32)], 'excess_loss': [0.06745334041530293, 0.051698095120574106, 0.05970857691955134], 'risk': [0.40227381030633697, 0.26859024556847144, 0.18599321790480983, 0.15270518587195625], 'train_loss': [0.2753333333333333, 0.19135, 0.18353333333333333, 0.17743333333333333], 'test_loss': [0.2479, 0.1955, 0.1777, 0.2043]}\n",
      "Et_loss_seed 3 [array([0.8829905 , 0.06594285, 0.06594285], dtype=float32), array([0.93648887, 0.05351111, 0.05351111], dtype=float32), array([0.9436, 0.0568, 0.0568], dtype=float32)]\n",
      "result_seed:  1 {'loss': [0.2509166666666667, array([0.88405716, 0.06643809, 0.06643809], dtype=float32), array([0.9384222, 0.0614   , 0.0614   ], dtype=float32), array([0.9281333 , 0.05163333, 0.05163333], dtype=float32)], 'kl': [array(2970.6882, dtype=float32), array(383.1022, dtype=float32), array(86.83548, dtype=float32), array(50.746483, dtype=float32)], 'excess_loss': [0.06827992985615838, 0.0618508401718284, 0.04703495190650209], 'risk': [0.4075726771403609, 0.27206626842633885, 0.19788397438499783, 0.145976939099001], 'train_loss': [0.2710166666666667, 0.18741666666666668, 0.20016666666666666, 0.18661666666666665], 'test_loss': [0.2611, 0.1916, 0.1968, 0.1853]}\n",
      "Et_loss_seed 3 [array([0.88405716, 0.06643809, 0.06643809], dtype=float32), array([0.9384222, 0.0614   , 0.0614   ], dtype=float32), array([0.9281333 , 0.05163333, 0.05163333], dtype=float32)]\n",
      "result_seed:  2 {'loss': [0.26158333333333333, array([0.8626095 , 0.07095238, 0.07095238], dtype=float32), array([0.93333334, 0.05351111, 0.05351111], dtype=float32), array([0.935     , 0.07146667, 0.07146667], dtype=float32)], 'kl': [array(2919.4224, dtype=float32), array(363.2266, dtype=float32), array(97.03565, dtype=float32), array(50.549717, dtype=float32)], 'excess_loss': [0.0633946791333243, 0.051832845619134926, 0.07277775062798308], 'risk': [0.4179950714507623, 0.27239221485870546, 0.18802895304848766, 0.1667922271522269], 'train_loss': [0.26613333333333333, 0.19201666666666667, 0.18723333333333333, 0.18895], 'test_loss': [0.2926, 0.1907, 0.1833, 0.1914]}\n",
      "Et_loss_seed 3 [array([0.8626095 , 0.07095238, 0.07095238], dtype=float32), array([0.93333334, 0.05351111, 0.05351111], dtype=float32), array([0.935     , 0.07146667, 0.07146667], dtype=float32)]\n",
      "result_seed:  3 {'loss': [0.25116666666666665, array([0.87670475, 0.06510476, 0.06510476], dtype=float32), array([0.9344    , 0.05628889, 0.05628889], dtype=float32), array([0.9389, 0.0585, 0.0585], dtype=float32)], 'kl': [array(2862.438, dtype=float32), array(399.42023, dtype=float32), array(75.2236, dtype=float32), array(43.715775, dtype=float32)], 'excess_loss': [0.06474256747834528, 0.05274313382911622, 0.05816741539323034], 'risk': [0.4049306791269742, 0.2672079070418324, 0.18634708735003241, 0.15134095906824654], 'train_loss': [0.2643, 0.19801666666666667, 0.18385, 0.17763333333333334], 'test_loss': [0.2584, 0.1849, 0.1886, 0.1854]}\n",
      "Et_loss_seed 3 [array([0.87670475, 0.06510476, 0.06510476], dtype=float32), array([0.9344    , 0.05628889, 0.05628889], dtype=float32), array([0.9389, 0.0585, 0.0585], dtype=float32)]\n",
      "result_seed:  4 {'loss': [0.25293333333333334, array([0.8761714 , 0.07047619, 0.07047619], dtype=float32), array([0.9258222 , 0.05771111, 0.05771111], dtype=float32), array([0.92826664, 0.06956667, 0.06956667], dtype=float32)], 'kl': [array(2901.5957, dtype=float32), array(354.8089, dtype=float32), array(90.17029, dtype=float32), array(51.874176, dtype=float32)], 'excess_loss': [0.06789501840309287, 0.052667898777963074, 0.06803210224346223], 'risk': [0.4079536954445183, 0.271871866125352, 0.18860383184063909, 0.1623340181637818], 'train_loss': [0.28831666666666667, 0.1854, 0.1913, 0.17506666666666668], 'test_loss': [0.2442, 0.1885, 0.189, 0.1962]}\n",
      "Et_loss_seed 3 [array([0.8761714 , 0.07047619, 0.07047619], dtype=float32), array([0.9258222 , 0.05771111, 0.05771111], dtype=float32), array([0.92826664, 0.06956667, 0.06956667], dtype=float32)]\n",
      "train_loss:  0.18114  ;  0.0055481788803975\n",
      "B_1 loss:  0.2524966666666667  ;  0.005113896101147668\n",
      "B_1_kln:  0.04878780924479166  ;  0.0007388514424462997\n",
      "risks:  0.1558298658710425  ;  0.007608829571786274\n",
      "test_loss:  0.19252  ;  0.007160837939794481\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Stats of Recursive-T \"\"\"\n",
    "T_splits = [7500, 7500, 15000, 30000]#[1875, 1875, 3750, 7500, 15000, 30000]\n",
    "T = len(T_splits)\n",
    "n_total = 60000\n",
    "n_bound = [n_total_i - T_splits_i for n_total_i , T_splits_i in zip([60000]*T,T_splits)]# ; print(\"n_bound\", n_bound)\n",
    "mc_samples = n_bound\n",
    "delta_test=0.01\n",
    "delta=0.025\n",
    "method = \"Recursive-T\"\n",
    "name_data = \"fmnist\"\n",
    "model = \"cnn\"\n",
    "objective = \"fclassic\"\n",
    "seeds = np.arange(5)\n",
    "# Excess loss\n",
    "gamma_t = 0.5\n",
    "rv = np.array([-gamma_t, 0, 1-gamma_t, 1])\n",
    "js = rv[1:]# ; print(\"js\", js)\n",
    "js_minus = rv[1:] - rv[0:-1]# ; print(\"js_minus\", js_minus)\n",
    "\n",
    "\n",
    "# B1\n",
    "B_1_loss = []\n",
    "B_1_kln = []\n",
    "B_1_risk = []\n",
    "\n",
    "# Et\n",
    "Et_loss = []\n",
    "Et_kln = []\n",
    "Et_risk = []\n",
    "\n",
    "kln = [] # kl/n\n",
    "train_loss = []\n",
    "eval_loss = []\n",
    "excess_loss = []\n",
    "h_loss = []\n",
    "test_loss = []\n",
    "risks = [] # the risk\n",
    "excess_risks = [] # the excess risk\n",
    "h_risks = [] # reference classifier h risks\n",
    "\n",
    "for seed in seeds:\n",
    "    exp_settings = f\"{name_data}_{model}_{objective}_{T}_{seed}.pt\"\n",
    "    results_dir = f\"./results/{method}/results_\" + exp_settings\n",
    "\n",
    "    with open(results_dir, \"rb\") as handle:\n",
    "        result_seed = pickle.load(handle)\n",
    "    print(\"result_seed: \", seed, result_seed)\n",
    "\n",
    "    # Basic for last posterior\n",
    "    risks.append(result_seed[\"risk\"][-1])\n",
    "    train_loss.append(result_seed[\"train_loss\"][-1])\n",
    "    test_loss.append(result_seed[\"test_loss\"][-1])\n",
    "\n",
    "    # More statistics\n",
    "    ## B_1\n",
    "    B_1_loss_seed = result_seed[\"loss\"][0]# ; print(\"B_1_loss_seed\", B_1_loss_seed)\n",
    "    B_1_loss.append(B_1_loss_seed)\n",
    "    B_1_kl_seed = result_seed[\"kl\"][0]# ; print(\"B_1_kl_seed\", B_1_kl_seed)\n",
    "    B_1_kln.append(B_1_kl_seed/n_total)\n",
    "    B_1_risk.append(result_seed[\"risk\"][0])\n",
    "    #B_1_risk_seed = solve_kl_sup(B_1_loss_seed, np.log(T / delta_test) / n_total)# ; print(\"B_1_risk_seed\", B_1_risk_seed)\n",
    "    #B_1_risk_seed = solve_kl_sup(B_1_risk_seed, (B_1_kl_seed + np.log((2 * T * np.sqrt(n_total)) / delta)) / n_total)\n",
    "    #print(\"B_1_risk_seed \", B_1_risk_seed, \" risk recorded \", result_seed[\"risk\"][0])\n",
    "    #Excess_Et_seed = result_seed[\"loss\"][1:] ; print(\"Excess_Et_seed\", Excess_Et_seed)\n",
    "    \n",
    "\n",
    "    ## excess risk\n",
    "    Et_loss_seed = result_seed[\"loss\"][1:] ; print(\"Et_loss_seed\", Et_loss_seed)\n",
    "    for t in range(T):\n",
    "        \n",
    "    #excess_loss_T_seed = result_seed[\"risk\"][1:]\n",
    "    #excess_loss_2_seed = result_seed[\"risk\"][2][1]\n",
    "    #excess_loss_seed = rv[0] + js_minus[0] * excess_loss_1_seed + js_minus[1] * excess_loss_2_seed\n",
    "    #excess_loss.append(excess_loss_seed)\n",
    "    #kl_seed = result_seed[\"kl\"] ; kln.append(kl_seed/n_bound)\n",
    "\n",
    "    # h risk\n",
    "    #h_loss_seed = result_seed[\"risk\"][3] ; h_loss.append(h_loss_seed)\n",
    "\n",
    "# Train loss\n",
    "print(\"train_loss: \", np.mean(train_loss), \" ; \", np.std(train_loss))\n",
    "# For bound\n",
    "## B_1\n",
    "print(\"B_1 loss: \", np.mean(B_1_loss), \" ; \", np.std(B_1_loss))\n",
    "print(\"B_1_kln: \", np.mean(B_1_kln), \" ; \", np.std(B_1_kln))\n",
    "## excess bound\n",
    "#print(\"kln: \", np.mean(kln),\" ; \", np.std(kln))\n",
    "#print(\"excess_loss: \", np.mean(excess_loss), \" ; \", np.std(excess_loss))\n",
    "#print(\"excess_risk: \", np.mean(excess_risks),\" ; \", np.std(excess_risks))\n",
    "## h bound\n",
    "#print(\"h_loss: \", np.mean(h_loss), \" ; \", np.std(h_loss))\n",
    "#print(\"h_risks: \", np.mean(h_risks), \" ; \", np.std(h_risks))\n",
    "## bound\n",
    "print(\"risks: \", np.mean(risks), \" ; \", np.std(risks))\n",
    "# Test loss\n",
    "print(\"test_loss: \", np.mean(test_loss), \" ; \", np.std(test_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pbb_tight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
