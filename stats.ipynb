{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and stats for Uninformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- basic stats ----\n",
      "train_loss:  0.3655233333333333  ;  0.0019627814730914716\n",
      "test_loss:  0.35832  ;  0.003497656358191872\n",
      "risks:  0.4778762421327808  ;  0.001957785750838015\n",
      "---- further details ----\n",
      "train_loss:  0.3655233333333333  ;  0.0019627814730914716\n",
      "eval_loss:  0.3655233333333333  ;  0.0019627814730914716\n",
      "kln:  0.022833062337239585  ;  7.562504371881661e-05\n",
      "risks:  0.4778762421327808  ;  0.001957785750838015\n",
      "test_loss:  0.35832  ;  0.003497656358191872\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Stats of Uninformed \"\"\"\n",
    "method = \"Uninformed\"\n",
    "name_data = \"mnist\" # mnist or fmnist\n",
    "model = \"fcn\" # fcn or cnn\n",
    "objective = \"fclassic\"\n",
    "seeds = np.arange(5)\n",
    "n_bound = 60000\n",
    "mc_samples = 60000\n",
    "delta_test=0.01\n",
    "delta=0.025\n",
    "\n",
    "kln = []\n",
    "risks = []\n",
    "train_loss = []\n",
    "eval_loss = []\n",
    "test_loss = []\n",
    "for seed in seeds:\n",
    "    exp_settings = f\"{name_data}_{model}_{objective}_{seed}.pt\"\n",
    "    results_dir = f\"./results/{method}/results_\" + exp_settings\n",
    "\n",
    "    with open(results_dir, \"rb\") as handle:\n",
    "        result_seed = pickle.load(handle)\n",
    "    ## read results\n",
    "    risks.append(result_seed[\"risk\"])\n",
    "    train_loss.append(result_seed[\"train_loss\"])\n",
    "    eval_loss.append(result_seed[\"train_loss\"]) # should be eval_loss\n",
    "    test_loss.append(result_seed[\"test_loss\"])\n",
    "    kln.append(result_seed[\"kl\"]/n_bound)\n",
    "\n",
    "# basic stats\n",
    "print(\"---- basic stats ----\")\n",
    "print(\"train_loss: \", np.mean(train_loss), \" ; \", np.std(train_loss))\n",
    "print(\"test_loss: \", np.mean(test_loss), \" ; \", np.std(test_loss))\n",
    "print(\"risks: \", np.mean(risks), \" ; \", np.std(risks))\n",
    "\n",
    "# further details\n",
    "print(\"---- further details ----\")\n",
    "## train loss\n",
    "print(\"train_loss: \", np.mean(train_loss), \" ; \", np.std(train_loss))\n",
    "## for bound\n",
    "print(\"eval_loss: \", np.mean(eval_loss), \" ; \", np.std(eval_loss))\n",
    "print(\"kln: \", np.mean(kln),\" ; \", np.std(kln))\n",
    "print(\"risks: \", np.mean(risks), \" ; \", np.std(risks))\n",
    "## test loss\n",
    "print(\"test_loss: \", np.mean(test_loss), \" ; \", np.std(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and stats for Informed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result_seed:  0 {'kl': array(80.83292, dtype=float32), 'risk': 0.3837803676549357, 'train_loss': 0.3415, 'eval_loss': 0.3379666666666667, 'test_loss': 0.34}\n",
      "result_seed:  1 {'kl': array(86.555855, dtype=float32), 'risk': 0.38910774574478296, 'train_loss': 0.34203333333333336, 'eval_loss': 0.342, 'test_loss': 0.3291}\n",
      "result_seed:  2 {'kl': array(81.00739, dtype=float32), 'risk': 0.3796732592069954, 'train_loss': 0.3402, 'eval_loss': 0.33393333333333336, 'test_loss': 0.3377}\n",
      "result_seed:  3 {'kl': array(82.6727, dtype=float32), 'risk': 0.3849526530601304, 'train_loss': 0.33741666666666664, 'eval_loss': 0.33873333333333333, 'test_loss': 0.3328}\n",
      "result_seed:  4 {'kl': array(80.542496, dtype=float32), 'risk': 0.38673049442256374, 'train_loss': 0.3463833333333333, 'eval_loss': 0.3409, 'test_loss': 0.3394}\n",
      "---- basic stats ----\n",
      "train_loss:  0.3415066666666667  ;  0.002915296821175431\n",
      "test_loss:  0.3358  ;  0.004197618372363074\n",
      "risks:  0.38484890401788163  ;  0.003150172958329321\n",
      "---- further details ----\n",
      "train_loss:  0.3415066666666667  ;  0.002915296821175431\n",
      "eval_loss:  0.33870666666666666  ;  0.0027924819704978425\n",
      "kln:  0.002744075724283854  ;  7.477479307773228e-05\n",
      "risks:  0.38484890401788163  ;  0.003150172958329321\n",
      "test_loss:  0.3358  ;  0.004197618372363074\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Stats of Informed \"\"\"\n",
    "method = \"Informed\"\n",
    "name_data = \"mnist\"\n",
    "model = \"fcn\"\n",
    "objective = \"fclassic\"\n",
    "seeds = np.arange(5)\n",
    "n_bound = 30000\n",
    "mc_samples = 30000\n",
    "delta_test=0.01\n",
    "delta=0.025\n",
    "\n",
    "kln = []\n",
    "risks = []\n",
    "train_loss = []\n",
    "eval_loss = []\n",
    "test_loss = []\n",
    "for seed in seeds:\n",
    "    exp_settings = f\"{name_data}_{model}_{objective}_{seed}.pt\"\n",
    "    results_dir = f\"./results/{method}/results_\" + exp_settings\n",
    "\n",
    "    with open(results_dir, \"rb\") as handle:\n",
    "        result_seed = pickle.load(handle)\n",
    "    \n",
    "    print(\"result_seed: \", seed, result_seed)\n",
    "    ## read results\n",
    "    risks.append(result_seed[\"risk\"])\n",
    "    train_loss.append(result_seed[\"train_loss\"])\n",
    "    eval_loss.append(result_seed[\"eval_loss\"])\n",
    "    test_loss.append(result_seed[\"test_loss\"])\n",
    "    kln.append(result_seed[\"kl\"]/n_bound)\n",
    "\n",
    "# basic stats\n",
    "print(\"---- basic stats ----\")\n",
    "print(\"train_loss: \", np.mean(train_loss), \" ; \", np.std(train_loss))\n",
    "print(\"test_loss: \", np.mean(test_loss), \" ; \", np.std(test_loss))\n",
    "print(\"risks: \", np.mean(risks), \" ; \", np.std(risks))\n",
    "\n",
    "# further details\n",
    "print(\"---- further details ----\")\n",
    "## Train loss\n",
    "print(\"train_loss: \", np.mean(train_loss), \" ; \", np.std(train_loss))\n",
    "## For bound\n",
    "print(\"eval_loss: \", np.mean(eval_loss), \" ; \", np.std(eval_loss))\n",
    "print(\"kln: \", np.mean(kln),\" ; \", np.std(kln))\n",
    "print(\"risks: \", np.mean(risks), \" ; \", np.std(risks))\n",
    "## Test loss\n",
    "print(\"test_loss: \", np.mean(test_loss), \" ; \", np.std(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and stats for InformedExcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result_seed:  0 {'kl': array(2257.233, dtype=float32), 'risk': (0.3705466478844455, 0.027586265624620698, array([0.99473333, 0.162     ], dtype=float32), 0.024833333333333332), 'train_loss': 0.17886666666666667, 'eval_loss': 0.1956, 'test_loss': 0.1728}\n",
      "result_seed:  1 {'kl': array(2294.978, dtype=float32), 'risk': (0.3520138451579917, 0.02772651851628119, array([0.995     , 0.14586666], dtype=float32), 0.024966666666666668), 'train_loss': 0.16718333333333332, 'eval_loss': 0.18523333333333333, 'test_loss': 0.1628}\n",
      "result_seed:  2 {'kl': array(2210.3599, dtype=float32), 'risk': (0.35870430111039253, 0.028182203222536065, array([0.995     , 0.15366666], dtype=float32), 0.0254), 'train_loss': 0.17398333333333332, 'eval_loss': 0.1913, 'test_loss': 0.1704}\n",
      "result_seed:  3 {'kl': array(2274.2197, dtype=float32), 'risk': (0.35437947337471476, 0.02737584847988072, array([0.9948, 0.1487], dtype=float32), 0.024633333333333333), 'train_loss': 0.16993333333333333, 'eval_loss': 0.18553333333333333, 'test_loss': 0.1642}\n",
      "result_seed:  4 {'kl': array(2380.976, dtype=float32), 'risk': (0.3489475298631154, 0.02881281255583679, array([0.99476665, 0.1398    ], dtype=float32), 0.026), 'train_loss': 0.15955, 'eval_loss': 0.1772, 'test_loss': 0.1563}\n",
      "---- basic stats ----\n",
      "train_loss:  0.16990333333333332  ;  0.006505052736996922\n",
      "test_loss:  0.1653  ;  0.00584328674634405\n",
      "risks:  0.356918359478132  ;  0.0075226878243579015\n",
      "---- further details ----\n",
      "train_loss:  0.16990333333333332  ;  0.006505052736996922\n",
      "kln:  0.07611844401041666  ;  0.0018713559566793257\n",
      "excess_loss:  0.1448666572570801  ;  0.007472830593175006\n",
      "excess_risk:  0.3289816297983009  ;  0.007771684610989046\n",
      "h_loss:  0.025166666666666664  ;  0.00048671232662517226\n",
      "h_risks:  0.02793672967983109  ;  0.0005117382091522643\n",
      "risks:  0.356918359478132  ;  0.0075226878243579015\n",
      "test_loss:  0.1653  ;  0.00584328674634405\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Stats of InformedExcess \"\"\"\n",
    "method = \"InformedExcess\"\n",
    "name_data = \"mnist\" # mnist or fmnist\n",
    "model = \"fcn\" # fcn or cnn\n",
    "objective = \"fclassic\"\n",
    "seeds = np.arange(5)\n",
    "n_bound = 30000\n",
    "mc_samples = 30000\n",
    "delta_test=0.01\n",
    "delta=0.025\n",
    "# Excess loss\n",
    "rv = np.array([-1, 0, 1])\n",
    "js = rv[1:]\n",
    "js_minus = rv[1:] - rv[0:-1]\n",
    "\n",
    "kln = [] # kl/n\n",
    "train_loss = []\n",
    "eval_loss = []\n",
    "excess_loss = []\n",
    "h_loss = []\n",
    "test_loss = []\n",
    "risks = [] # the risk\n",
    "excess_risks = [] # the excess risk\n",
    "h_risks = [] # reference classifier h risks\n",
    "\n",
    "for seed in seeds:\n",
    "    exp_settings = f\"{name_data}_{model}_{objective}_{seed}.pt\"\n",
    "    results_dir = f\"./results/{method}/results_\" + exp_settings\n",
    "\n",
    "    with open(results_dir, \"rb\") as handle:\n",
    "        result_seed = pickle.load(handle)\n",
    "    print(\"result_seed: \", seed, result_seed)\n",
    "\n",
    "    # Basic\n",
    "    risks.append(result_seed[\"risk\"][0])\n",
    "    h_risks.append(result_seed[\"risk\"][1])\n",
    "    excess_risks.append(result_seed[\"risk\"][0] - result_seed[\"risk\"][1])\n",
    "    train_loss.append(result_seed[\"train_loss\"])\n",
    "    test_loss.append(result_seed[\"test_loss\"])\n",
    "\n",
    "    # excess risk\n",
    "    excess_loss_1_seed = result_seed[\"risk\"][2][0]\n",
    "    excess_loss_2_seed = result_seed[\"risk\"][2][1]\n",
    "    excess_loss_seed = rv[0] + js_minus[0] * excess_loss_1_seed + js_minus[1] * excess_loss_2_seed\n",
    "    excess_loss.append(excess_loss_seed)\n",
    "    kl_seed = result_seed[\"kl\"] ; kln.append(kl_seed/n_bound)\n",
    "\n",
    "    # h risk\n",
    "    h_loss_seed = result_seed[\"risk\"][3] ; h_loss.append(h_loss_seed)\n",
    "\n",
    "# basic stats\n",
    "print(\"---- basic stats ----\")\n",
    "print(\"train_loss: \", np.mean(train_loss), \" ; \", np.std(train_loss))\n",
    "print(\"test_loss: \", np.mean(test_loss), \" ; \", np.std(test_loss))\n",
    "print(\"risks: \", np.mean(risks), \" ; \", np.std(risks))\n",
    "\n",
    "# further details\n",
    "print(\"---- further details ----\")\n",
    "## Train loss\n",
    "print(\"train_loss: \", np.mean(train_loss), \" ; \", np.std(train_loss))\n",
    "## For bound\n",
    "### excess bound\n",
    "print(\"kln: \", np.mean(kln),\" ; \", np.std(kln))\n",
    "print(\"excess_loss: \", np.mean(excess_loss), \" ; \", np.std(excess_loss))\n",
    "print(\"excess_risk: \", np.mean(excess_risks),\" ; \", np.std(excess_risks))\n",
    "### h bound\n",
    "print(\"h_loss: \", np.mean(h_loss), \" ; \", np.std(h_loss))\n",
    "print(\"h_risks: \", np.mean(h_risks), \" ; \", np.std(h_risks))\n",
    "### bound\n",
    "print(\"risks: \", np.mean(risks), \" ; \", np.std(risks))\n",
    "## Test loss\n",
    "print(\"test_loss: \", np.mean(test_loss), \" ; \", np.std(test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results and stats for Recursive PAC-Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_posteriors:  [60000, 59532, 59063, 58125, 56250, 52500, 45000, 30000]\n"
     ]
    }
   ],
   "source": [
    "method = \"rpb\"\n",
    "name_data = \"mnist\" # mnist or fmnist\n",
    "model = \"fcn\" # fcn or cnn\n",
    "layers = 4\n",
    "objective = \"fclassic\"\n",
    "\n",
    "T = 8 # 2, 4, 6, or 8\n",
    "if T == 2:\n",
    "    split = \"uniform\"\n",
    "else:\n",
    "    split = \"geometric\"\n",
    "\n",
    "n_train = 60000\n",
    "if split == \"uniform\":\n",
    "    T_splits = [int(n_train / T)] * (T-1)\n",
    "    T_splits.append(n_train - int(n_train / T)*(T-1))\n",
    "elif split == \"geometric\":\n",
    "    if T == 2:\n",
    "        T_splits = [20000, 40000]\n",
    "    elif T == 4:\n",
    "        T_splits = [7500, 7500, 15000, 30000]\n",
    "    elif T == 6:\n",
    "        T_splits = [1875, 1875, 3750, 7500, 15000, 30000]\n",
    "    elif T == 8:\n",
    "        T_splits = [468, 469, 938, 1875, 3750, 7500, 15000, 30000]\n",
    "n_train_t_cumsum = np.cumsum(T_splits)\n",
    "n_posteriors = [n_train - n_train_t_cumsum[t - 2] for t in range(1, T + 1)]\n",
    "n_posteriors[0] = n_train\n",
    "print(\"n_posteriors: \", n_posteriors)\n",
    "\n",
    "gamma_t = 0.5\n",
    "# Excess loss\n",
    "rv = np.array([-gamma_t, 0, 1-gamma_t, 1])\n",
    "js = rv[1:]\n",
    "js_minus = rv[1:] - rv[0:-1]\n",
    "\n",
    "recursive_step_1 = False # Use B_1\n",
    "risk_laststep = False\n",
    "seeds = np.arange(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- basic stats ----\n",
      "train_loss:  0.09696666666666667  ;  0.0\n",
      "test_loss:  0.0942  ;  0.0\n",
      "risks:  0.1763910859890787  ;  0.0\n"
     ]
    }
   ],
   "source": [
    "kl_seeds = []\n",
    "excess_risk_seeds = []\n",
    "risk_seeds = []\n",
    "train_loss_seeds = []\n",
    "test_loss_seeds = []\n",
    "for seed in seeds:\n",
    "\n",
    "    exp_settings = f\"{name_data}_{model}_{layers}_{objective}_{split}_{T}_{recursive_step_1}_{risk_laststep}_{gamma_t}_{seed}.pt\"\n",
    "\n",
    "    results_dir = f\"./results/rpb/results_\" + exp_settings\n",
    "    with open(results_dir, \"rb\") as handle:\n",
    "        results = pickle.load(handle)\n",
    "\n",
    "    kl_seeds.append(results[\"kl\"])\n",
    "    excess_risk_seeds.append(results[\"excess_risk\"]) # E_t\n",
    "    risk_seeds.append(results[\"risk\"]) # B_t\n",
    "    train_loss_seeds.append(results[\"train_loss\"])\n",
    "    test_loss_seeds.append(results[\"test_loss\"])\n",
    "\n",
    "kl_seeds = np.array(kl_seeds)\n",
    "excess_risk_seeds = np.array(excess_risk_seeds)\n",
    "risk_seeds = np.array(risk_seeds)\n",
    "train_loss_seeds = np.array(train_loss_seeds)\n",
    "test_loss_seeds = np.array(test_loss_seeds)\n",
    "\n",
    "# basic stats\n",
    "print(\"---- basic stats ----\")\n",
    "print(\"train_loss: \", train_loss_seeds.mean(0), \" ; \", train_loss_seeds.std(0))\n",
    "print(\"test_loss: \", test_loss_seeds.mean(0)[-1], \" ; \", test_loss_seeds.std(0)[-1])\n",
    "print(\"risks: \", risk_seeds.mean(0)[-1], \" ; \", risk_seeds.std(0)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- further details ----\n",
      "test_loss in rpb\n",
      "mean:  [0.34166 0.13638 0.11482 0.10584 0.098   0.09554]\n",
      "std:  [0.00452    0.00320337 0.00216185 0.00217954 0.00186869 0.0017625 ]\n",
      "B_t in rpb\n",
      "mean:  [0.45416848 0.38498419 0.30313124 0.24420018 0.20476847 0.18565702]\n",
      "std:  [0.0057251  0.00335994 0.00181273 0.00193779 0.00162876 0.00202064]\n",
      "E_t in rpb\n",
      "mean:  [0.15789995 0.11063915 0.09263456 0.08266838 0.08327278]\n",
      "std:  [0.00309851 0.0022632  0.00129615 0.00144103 0.0025285 ]\n",
      "kln in rpb\n",
      "mean:  [0.01871792 0.05630976 0.00963022 0.00437401 0.00318368 0.00264056]\n",
      "std:  [0.00024784 0.00110821 0.00034405 0.00028584 0.00010943 0.00012382]\n"
     ]
    }
   ],
   "source": [
    "print(\"---- further details ----\")\n",
    "print(\"test_loss in rpb\")\n",
    "print(\"mean: \", test_loss_seeds.mean(0))\n",
    "print(\"std: \", test_loss_seeds.std(0))\n",
    "print(\"B_t in rpb\")\n",
    "print(\"mean: \", risk_seeds.mean(0))\n",
    "print(\"std: \", risk_seeds.std(0))\n",
    "print(\"E_t in rpb\")\n",
    "print(\"mean: \", excess_risk_seeds.mean(0))\n",
    "print(\"std: \", excess_risk_seeds.std(0))\n",
    "print(\"kln in rpb\")\n",
    "print(\"mean: \", (kl_seeds / n_posteriors).mean(0))\n",
    "print(\"std: \", (kl_seeds / n_posteriors).std(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More on excess losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.36043333333333333,\n",
       " array([0.74940217, 0.14298494, 0.03363441], dtype=float32),\n",
       " array([0.9346667 , 0.11953778, 0.04177778], dtype=float32),\n",
       " array([0.95125717, 0.11177143, 0.03944762], dtype=float32),\n",
       " array([0.9535111 , 0.10024445, 0.0344    ], dtype=float32),\n",
       " array([0.9631    , 0.1033    , 0.03763333], dtype=float32)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emp loss for B1 is  0.36043333333333333  with B_t  0.4541684779633818\n",
      "excess loss t =  1  is  -0.0369892418384552  with E_t  0.1578999483098555\n",
      "excess loss t =  2  is  0.04799112491309643  with E_t  0.11063914958110883\n",
      "excess loss t =  3  is  0.051238108426332474  with E_t  0.09263455925429699\n",
      "excess loss t =  4  is  0.044077783823013306  with E_t  0.08266838015835745\n",
      "excess loss t =  5  is  0.05201667360961437  with E_t  0.08327278171601249\n"
     ]
    }
   ],
   "source": [
    "print(\"emp loss for B1 is \", results[\"loss\"][0], \" with B_t \", risk_seeds.mean(0)[0])\n",
    "for t in range(1, T):\n",
    "    exc = (results[\"loss\"][t] * js_minus).sum(0) + rv[0]\n",
    "    print(\"excess loss t = \", t, \" is \", exc, \" with E_t \", excess_risk_seeds.mean(0)[t-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def KL(Q, P):\n",
    "    \"\"\"\n",
    "    Compute Kullback-Leibler (KL) divergence between distributions Q and P.\n",
    "    \"\"\"\n",
    "    return sum([q * np.log(q / p) if q > 0.0 else 0.0 for q, p in zip(Q, P)])\n",
    "\n",
    "\n",
    "def KL_binomial(q, p):\n",
    "    \"\"\"\n",
    "    Compute the KL-divergence between two Bernoulli distributions of probability\n",
    "    of success q and p. That is, Q=(q,1-q), P=(p,1-p).\n",
    "    \"\"\"\n",
    "    return KL([q, 1.0 - q], [p, 1.0 - p])\n",
    "\n",
    "\n",
    "def get_binominal_inv(n, k, delta):\n",
    "    for p in np.linspace(1, 0, 100001):\n",
    "        if binom.pmf(k, n, p) >= delta:\n",
    "            return p\n",
    "\n",
    "\n",
    "def solve_kl_sup(q, right_hand_side):\n",
    "    \"\"\"\n",
    "    find x such that:\n",
    "        kl( q || x ) = right_hand_side\n",
    "        x > q\n",
    "    \"\"\"\n",
    "    f = lambda x: KL_binomial(q, x) - right_hand_side\n",
    "\n",
    "    if f(1.0 - 1e-9) <= 0.0:\n",
    "        return 1.0 - 1e-9\n",
    "    else:\n",
    "        return optimize.brentq(f, q, 1.0 - 1e-11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pbb_tight",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
